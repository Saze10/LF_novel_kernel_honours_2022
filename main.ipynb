{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "057e877d",
   "metadata": {},
   "source": [
    "# 2022 Sydney University Honours project - Novel kernels for deep learning on light field images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7ef404d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensorflow version:  2.9.1\n",
      "Num GPUs Available:  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-10 17:33:27.959721: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-10 17:33:27.985668: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-10 17:33:27.985812: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import PIL\n",
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import matplotlib.pyplot as plt\n",
    "import sys, glob, os, random\n",
    "import pandas as pd\n",
    "import scipy.io as sio\n",
    "import preprocessing.flatten\n",
    "import preprocessing.hci_dataset_tools.file_io as hci_io\n",
    "print('tensorflow version: ', tf.__version__)\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95b87733",
   "metadata": {},
   "source": [
    "## Data Loading and Prepreprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "157d17f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '../../datasets'\n",
    "hci_boxes = '/hci_dataset/training/boxes/'\n",
    "hci_boxes_stacked = '/hci_dataset/training/boxes/stacked/'\n",
    "\n",
    "def load_dataset(num_imgs=1, read_dirs=[data_path+hci_boxes_stacked]):\n",
    "    '''\n",
    "    by default reads the boxes \n",
    "    '''\n",
    "    img_set = []\n",
    "    for i in range(num_imgs):\n",
    "        img = Image.open(read_dirs[i] + 'stacked.png')\n",
    "        img = np.asarray(img)\n",
    "        img_set.append(img)\n",
    "    img_set = np.asarray(img_set)\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(img_set)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4b2330b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disparity file read success:  ../../datasets/hci_dataset/training/boxes/gt_disp_lowres.pfm\n",
      "disparity shape: \n",
      " (512, 512)\n",
      "depth file read success:  ../../datasets/hci_dataset/training/boxes/gt_depth_lowres.pfm\n",
      "depth shape: \n",
      " (512, 512)\n",
      "(3038, 3038, 3)\n"
     ]
    }
   ],
   "source": [
    "data_path = '../../datasets'\n",
    "disparity = hci_io.read_disparity(data_path + hci_boxes)\n",
    "print('disparity shape: \\n', disparity.shape)\n",
    "depth = hci_io.read_depth(data_path + hci_boxes)\n",
    "print('depth shape: \\n', depth.shape)\n",
    "\n",
    "dataset = load_dataset()\n",
    "for elem in dataset:\n",
    "    print(elem.numpy().shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d74647a8",
   "metadata": {},
   "source": [
    "## Model init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "598a67a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " Conv1 (Conv2D)              (None, 13, 13, 8)         80        \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 1352)              0         \n",
      "                                                                 \n",
      " Dense (Dense)               (None, 10)                13530     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 13,610\n",
      "Trainable params: 13,610\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = keras.Sequential([\n",
    "keras.layers.Conv2D(input_shape=(28,28,1), filters=8, kernel_size=3, \n",
    "                      strides=2, activation='relu', name='Conv1'),\n",
    "                    keras.layers.Flatten(),\n",
    "                    keras.layers.Dense(10, name='Dense')\n",
    "])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb6187c9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
